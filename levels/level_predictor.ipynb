{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LOOK_BACK = 10 # how far the algorithm looks back into the past to try and predict the future price\n",
    "N_LOOK_AHEAD = 20 # how far into the future the algorithm tries to predict price movements\n",
    "TRADE_THRESHOLD = 0.002 # strength of the price movement to trigger a trade signal\n",
    "LIMIT = 10000 # limit the number of data points for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eurusd = pd.read_csv(\"data_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "eurusd[\"dt\"] = pd.to_datetime(eurusd[\"dt\"])\n",
    "eurusd.set_index(\"dt\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = pd.read_csv(\"trades_sample.csv\")\n",
    "trades[\"dt\"] = pd.to_datetime(trades[\"dt\"])\n",
    "trades.set_index(\"dt\", inplace=True)\n",
    "\n",
    "trades_u = trades.drop_duplicates(\"Order\")\n",
    "\n",
    "trades_u[\"SL_p\"] = trades_u[\"SL\"] / trades_u[\"Price\"] - 1\n",
    "trades_u[\"TP_p\"] = trades_u[\"TP\"] / trades_u[\"Price\"] - 1\n",
    "\n",
    "tp_sl = trades_u.groupby(\"Type\").agg({\"SL_p\": \"mean\", \"TP_p\": \"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eurusd.Close[:1000].plot(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_change = eurusd.Close.diff() / eurusd.Close.shift(1)\n",
    "rel_change = rel_change[1:][:(len(eurusd) - len(eurusd) % N_LOOK_BACK)][:LIMIT]\n",
    "N = len(rel_change)\n",
    "\n",
    "bins = rel_change.quantile(np.arange(0,1.1, 0.1))\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y = np.digitize(rel_change, bins.values)[N_LOOK_BACK-1::N_LOOK_BACK] - 1\n",
    "y_enc = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_idx = N - N % N_LOOK_BACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N%N_LOOK_BACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rel_change[:(cutoff_idx)].values.reshape(int((cutoff_idx) / N_LOOK_BACK), N_LOOK_BACK)[:,:-1]\n",
    "prices = eurusd.Close.values[1:(cutoff_idx)+1][:LIMIT].reshape(int((cutoff_idx) / N_LOOK_BACK), N_LOOK_BACK)[:,:-1]\n",
    "dates = eurusd.index.values[1:(cutoff_idx)+1][:LIMIT].reshape(int((cutoff_idx) / N_LOOK_BACK), N_LOOK_BACK)[:,:-1]\n",
    "\n",
    "\n",
    "TRAIN_FRAC = 0.7\n",
    "\n",
    "N_train = int(len(X) * TRAIN_FRAC)\n",
    "\n",
    "X_train = X[:N_train]\n",
    "y_train = y_enc[:N_train]\n",
    "X_test = X[N_train:]\n",
    "y_test = y_enc[N_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(objective='multi:softmax', \n",
    "                            num_class=len(np.unique(y_enc)), \n",
    "                            # missing=1, \n",
    "                            early_stopping_rounds=10, \n",
    "                            eval_metric=['merror','mlogloss'], \n",
    "                            seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf.fit(X_train, \n",
    "            y_train,\n",
    "            verbose=1,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)]\n",
    "    )\n",
    "# set to 1 to see xgb training round intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ar(prices, bins, model, X, n=10, beam_width=3):\n",
    "    X_c = X.copy()\n",
    "    \n",
    "    y_pred = bins.iloc[model.predict(X)]\n",
    "\n",
    "    groups = []\n",
    "\n",
    "    exp_price = prices[0][-1]\n",
    "\n",
    "    for i in range(1,n+1):\n",
    "        X_c = np.append(X_c, y_pred)\n",
    "        y_pred = bins.iloc[model.predict([X_c[i:]])]\n",
    "        exp_price *= float(y_pred) + 1.0\n",
    "        groups.append(y_pred)\n",
    "    \n",
    "    cum_change = sum([i.values[0] for i in groups])\n",
    "    \n",
    "    return X_c, groups, cum_change, exp_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, X_test.shape[0]-1):\n",
    "    pred, groups, cum_change, exp_price = predict_ar(prices[i:i+1], bins, xgb_clf, X_test[i:i+1], n=N_LOOK_AHEAD)\n",
    "    curr_price = prices[i:i+1][0][-1]\n",
    "    curr_date = dates[i:i+1][0][-1]\n",
    "    if abs(cum_change) > TRADE_THRESHOLD:\n",
    "        trade_type = \"Sell\" if np.sign(cum_change) else \"Buy\"\n",
    "        sl_rel = tp_sl.loc[trade_type][\"SL_p\"]\n",
    "        \n",
    "        sl =  curr_price * (1+sl_rel)\n",
    "\n",
    "        print(f\"\"\"\n",
    "              expected {N_LOOK_AHEAD}min cum_change: {round(cum_change*100, 2)}%, \n",
    "              trade type: {trade_type}, \n",
    "              target price/TP: {exp_price}, \n",
    "              current pirce: {curr_price},\n",
    "              current date: {curr_date}\n",
    "              SL: {sl}\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old Approach with Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(stock_prices, n_look_back, train_frac=0.8):\n",
    "    n = len(stock_prices)\n",
    "\n",
    "    data = stock_prices.values[:(n - n % n_look_back)].reshape(int((n - n % n_look_back)/n_look_back), n_look_back, stock_prices.shape[1])\n",
    "\n",
    "    print(data.shape)\n",
    "\n",
    "    N_train = int(len(data) * train_frac)\n",
    "\n",
    "    train_data = data[:N_train,:,:]\n",
    "    test_data = data[N_train:,:,:]\n",
    "\n",
    "    x_train = train_data[:,:-1,1]\n",
    "    y_train = train_data[:,-1,1].reshape(-1,1)\n",
    "    \n",
    "    x_test = test_data[:,:-1,1]\n",
    "    y_test = test_data[:,-1,1].reshape(-1,1)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(eurusd.Close.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(632453, 10, 4)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = prepare_data(eurusd, N_LOOK_BACK)\n",
    "\n",
    "x_train = torch.from_numpy(x_train).type(torch.Tensor)[:,:,None]\n",
    "x_test = torch.from_numpy(x_test).type(torch.Tensor)[:,:,None]\n",
    "y_train = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "hidden_dim = 32\n",
    "num_layers = 2 \n",
    "output_dim = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = data.DataLoader(data.TensorDataset(x_train, y_train), shuffle=True, batch_size=BATCH_SIZE) \n",
    "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 1\n",
    "\n",
    "hist = np.zeros(N_EPOCHS)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch \", epoch, \"MSE: \", loss.item())\n",
    "    hist[epoch] = loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_ar(X, n_frames=10):\n",
    "    inp = X[None,:,:]\n",
    "\n",
    "    print(inp.shape)\n",
    "\n",
    "    # for i in  range(n_frames):\n",
    "    for i in range(n_frames):\n",
    "        y_pred = model(inp[:,i:,:]).detach()[None]\n",
    "    # print(inp[i:], y_pred)\n",
    "        inp = torch.concat((inp, y_pred), dim=1)\n",
    "        # series = np.append(series, y_pred.detach().numpy())\n",
    "\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 1])\n"
     ]
    }
   ],
   "source": [
    "ar_predictions = pred_ar(x_test[0], n_frames=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ar_predictions[0,:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
